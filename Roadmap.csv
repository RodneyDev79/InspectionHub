Phase,Step,Task Description,Key Prompt / Checkpoint
1. Foundation,1.1: Database Schema,"Design a normalized SQLite database. Your CSV is flat, but a web app needs relational data (restaurants, inspections, violations all linked).","Prompt: ""Design a 3-table SQLite schema: restaurants (id, name, address, category), inspections (id, restaurant_id, date, score), and violations (id, inspection_id, violation_text, is_critical)."""
1. Foundation,1.2: Deep Scraper Refactor,"This is the most critical step. Your current script only scrapes the search results table. This is insufficient. It must be refactored to visit every single ""Details"" page.","Prompt: ""Refactor the HealthScraper class. It must first scrape the main table for restaurant knox_ids, then loop and visit each Details.aspx?id=... page. On the details page, it must scrape all history, scores, and all detailed violation text."""
1. Foundation,1.3: Data Normalization,Modify the refactored scraper to clean the scraped data and save it into the new 3-table normalized database (from 1.1).,Checkpoint: Your health_inspections.db file should be populated with linked data.
2. Bot Engine,"2.1: ""Diff"" Logic","Implement the ""diff"" (difference) logic. The scraper needs to check if an inspection (by restaurant_id, date, score) already exists in the database before adding it.","Prompt: ""Create a method in the scraper that returns a list of only the new_inspections (as dicts) that it found and added during its run."""
2. Bot Engine,2.2: Alerting Script,"Create a new bot.py script. This script will import the scraper, call its run() method, and get the new_inspections list.","Prompt: ""Create a bot.py that imports the scraper. If the scraper returns new inspections, format a tweet for each one (e.g., 'âœ… Health Score: {name} scored a {score} on {date}')."""
2. Bot Engine,2.3: Twitter API,Integrate the tweepy library into bot.py. Use os.environ.get() to read API keys so you never hardcode them.,Checkpoint: Can you run python bot.py and see it post a test tweet?
2. Bot Engine,2.4: Automation,Create a GitHub Actions workflow (.github/workflows/run-bot.yml).,"Prompt: ""Create a GitHub Action YAML file that runs on a daily schedule (cron). It must checkout the repo, install requirements.txt, run python bot.py, and then commit and push the updated health_inspections.db file back to GitHub."""
3. Video Engine,3.1: Video Assets,"Create your ""brand"" assets. You need a background video loop (template.mp4), a font (font.ttf), and maybe some background music (music.mp3).",Checkpoint: Do you have these static files ready?
3. Video Engine,3.2: Content Query,Create a video_generator.py. Its first job is to query the database.,"Prompt: ""Write a Python function using sqlite3 to query health_inspections.db and get 'The 5 Lowest Scores from the Past 7 Days'."""
3. Video Engine,3.3: Video Synthesis,Use the moviepy library to dynamically create the video.,"Prompt: ""Write a function using moviepy.editor. It should load template.mp4, and for each of the 5 low scores, create a TextClip with the restaurant name and score, set its start_time and duration, and composite it onto the main video."""
3. Video Engine,3.4: Final Export,Save the final composited video.,"Prompt: ""Add final_video.write_videofile('weekly_report.mp4') to the end of the script. Add this script to your GitHub Action to run weekly."""
4. Web App,4.1: Data API,"The web app will need to read the database. The simplest way is to have the GitHub Action save a ""live"" copy of the main health_inspections.db file.",Checkpoint: Does your GitHub Action correctly commit and push the .db file after each run?
4. Web App,4.2: Frontend App,Create an app.py using Streamlit.,"Prompt: ""Create a Streamlit app.py. It should load the health_inspections.db (using st.cache_data), provide a st.text_input for search, and display results (restaurant name, address, full inspection history) in a clean table."""
4. Web App,4.3: Visualizations,Use Streamlit's built-in chart and map functions.,"Prompt: ""Add an st.line_chart to show a single restaurant's score over time. Add an st.map to plot all restaurants, color-coded by their most recent score."""